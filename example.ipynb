{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8d8569a",
   "metadata": {},
   "source": [
    "## Login with Huggingface Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f8585a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76ce6a2d04464142bf37edbf7b42fe49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f159d695",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "900fd393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 0,\n",
      " 'ner_tags': [0, 0, 0, 1, 2, 0, 1, 0, 7, 8, 0, 1, 2, 2],\n",
      " 'tokens': ['his',\n",
      "            'playlist',\n",
      "            'includes',\n",
      "            'sonny',\n",
      "            'sharrock',\n",
      "            ',',\n",
      "            'gza',\n",
      "            ',',\n",
      "            'country',\n",
      "            'teasers',\n",
      "            'and',\n",
      "            'the',\n",
      "            'notorious',\n",
      "            'b.i.g.']}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from pprint import pprint\n",
    "\n",
    "raw_dataset = load_dataset('tomaarsen/MultiCoNER', 'multi')\n",
    "\n",
    "pprint(raw_dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0bf4c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 10,\n",
      " 'ner_tags': [0,\n",
      "              0,\n",
      "              0,\n",
      "              0,\n",
      "              0,\n",
      "              0,\n",
      "              0,\n",
      "              0,\n",
      "              0,\n",
      "              0,\n",
      "              11,\n",
      "              0,\n",
      "              0,\n",
      "              0,\n",
      "              0,\n",
      "              0,\n",
      "              0,\n",
      "              0,\n",
      "              0,\n",
      "              0,\n",
      "              0,\n",
      "              0,\n",
      "              0,\n",
      "              0,\n",
      "              0,\n",
      "              0],\n",
      " 'tokens': ['she',\n",
      "            'became',\n",
      "            'opposed',\n",
      "            'to',\n",
      "            'abortion',\n",
      "            'in',\n",
      "            '1992',\n",
      "            'while',\n",
      "            'attending',\n",
      "            'a',\n",
      "            'bible',\n",
      "            'study',\n",
      "            'and',\n",
      "            'has',\n",
      "            'since',\n",
      "            'spoken',\n",
      "            'out',\n",
      "            'about',\n",
      "            'how',\n",
      "            'abortion',\n",
      "            'has',\n",
      "            'negatively',\n",
      "            'impacted',\n",
      "            'her',\n",
      "            'life',\n",
      "            '.']}\n"
     ]
    }
   ],
   "source": [
    "pprint(raw_dataset['train'][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "000e7a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'B-PER',\n",
       " 'I-PER',\n",
       " 'B-LOC',\n",
       " 'I-LOC',\n",
       " 'B-CORP',\n",
       " 'I-CORP',\n",
       " 'B-GRP',\n",
       " 'I-GRP',\n",
       " 'B-PROD',\n",
       " 'I-PROD',\n",
       " 'B-CW',\n",
       " 'I-CW']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = raw_dataset['train'].features[f'ner_tags'].feature.names\n",
    "label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251bd866",
   "metadata": {},
   "source": [
    "# Load the Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87cc09df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('google-bert/bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "359fa0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['it', 'is', 'a', 'series', 'of', 'badminton', 'tournaments', ',', 'sanctioned', 'by', 'badminton', 'world', 'federation', '(', 'bwf', ')', 'since', '2007', '.']\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 8, 8, 0, 0, 0, 0, 0, 0]\n",
      "[None,\n",
      " 0,\n",
      " 1,\n",
      " 2,\n",
      " 3,\n",
      " 4,\n",
      " 5,\n",
      " 6,\n",
      " 7,\n",
      " 8,\n",
      " 9,\n",
      " 10,\n",
      " 11,\n",
      " 12,\n",
      " 13,\n",
      " 14,\n",
      " 14,\n",
      " 14,\n",
      " 15,\n",
      " 16,\n",
      " 17,\n",
      " 18,\n",
      " None]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'it',\n",
       " 'is',\n",
       " 'a',\n",
       " 'series',\n",
       " 'of',\n",
       " 'badminton',\n",
       " 'tournaments',\n",
       " ',',\n",
       " 'sanctioned',\n",
       " 'by',\n",
       " 'badminton',\n",
       " 'world',\n",
       " 'federation',\n",
       " '(',\n",
       " 'b',\n",
       " '##w',\n",
       " '##f',\n",
       " ')',\n",
       " 'since',\n",
       " '2007',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = raw_dataset['train'][1]\n",
    "print(example['tokens'])\n",
    "# Tokenize the first example in the training set\n",
    "tokenized_input = tokenizer(\n",
    "    example['tokens'],\n",
    "    truncation=True,\n",
    "    is_split_into_words=True,\n",
    ")\n",
    "word_ids = tokenized_input.word_ids(batch_index=0)\n",
    "pprint(example['ner_tags'])\n",
    "pprint(word_ids)\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input['input_ids'])\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4637ea39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    toeknized_inputs = tokenizer(examples['tokens'], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples['ner_tags']):\n",
    "        word_ids = toeknized_inputs.word_ids(batch_index=i)\n",
    "        # Map the token to the original label\n",
    "        previous_word_idx = None\n",
    "\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None. We set the label to -100 so they are ignored in loss\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif previous_word_idx is None or word_idx != previous_word_idx:\n",
    "                # Start of a new word\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                # Continuing the same word, repeat the previous label\n",
    "                label_ids.append(label[previous_word_idx])\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "        \n",
    "    toeknized_inputs['labels'] = labels\n",
    "    return toeknized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d72eb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 1117, 1505, 7276, 2075, 1488, 3382, 188, 7111, 10411, 117, 176, 3293, 117, 1583, 20826, 1733, 1105, 1103, 14140, 171, 119, 178, 119, 176, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, 0, 0, 0, 0, 1, 1, 2, 2, 2, 0, 1, 1, 0, 7, 8, 8, 0, 1, 2, 2, 2, 2, 2, 2, 2, -100]}\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = raw_dataset.map(tokenize_and_align_labels, batched=True, remove_columns=raw_dataset['train'].column_names)\n",
    "print(tokenized_datasets['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d6fb98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159\n"
     ]
    }
   ],
   "source": [
    "max_length = 0\n",
    "for i, example in enumerate(tokenized_datasets['train']):\n",
    "    if len(example['input_ids']) > max_length:\n",
    "        max_length = len(example['labels'])\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed411dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc2062e",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67d78ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "seqeval = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0adef321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "labels = [label_list[i] for i in example[f'ner_tags']]\n",
    "\n",
    "def compute_metrics(p):\n",
    "    \"\"\"\n",
    "    Computes the precision, recall, and F1 score of the model predictions.\n",
    "    \"\"\"\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)  # Get the predicted class indices\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for (prediction, label) in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for (prediction, label) in zip(predictions, labels)\n",
    "    ]\n",
    "    \n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962da7a4",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cea3c3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_TO_ID = {\n",
    "    \"O\": 0,\n",
    "    \"B-PER\": 1,\n",
    "    \"I-PER\": 2,\n",
    "    \"B-LOC\": 3,\n",
    "    \"I-LOC\": 4,\n",
    "    \"B-CORP\": 5,\n",
    "    \"I-CORP\": 6,\n",
    "    \"B-GRP\": 7,\n",
    "    \"I-GRP\": 8,\n",
    "    \"B-PROD\": 9,\n",
    "    \"I-PROD\": 10,\n",
    "    \"B-CW\": 11,\n",
    "    \"I-CW\": 12,\n",
    "}\n",
    "ID_TO_LABEL = {i: label for i, label in enumerate(LABEL_TO_ID)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f42ddedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights for loss function:\n",
      "O: 0.0111\n",
      "B-PER: 0.5688\n",
      "I-PER: 0.4536\n",
      "B-LOC: 0.4627\n",
      "I-LOC: 0.6537\n",
      "B-CORP: 0.7601\n",
      "I-CORP: 0.6668\n",
      "B-GRP: 0.7612\n",
      "I-GRP: 0.5372\n",
      "B-PROD: 0.7119\n",
      "I-PROD: 1.0000\n",
      "B-CW: 0.6515\n",
      "I-CW: 0.4118\n"
     ]
    }
   ],
   "source": [
    "weights = np.zeros(len(LABEL_TO_ID), dtype=np.float32)\n",
    "# pprint(tokenized_datasets)\n",
    "# pprint(tokenized_datasets['train'].features)\n",
    "# pprint(np.unique(tokenized_datasets['train'][0]['ner_tags'], return_counts=True))\n",
    "\n",
    "for i in range(len(tokenized_datasets['train'])):\n",
    "    unique, counts = np.unique(tokenized_datasets['train'][i]['ner_tags'], return_counts=True)\n",
    "    weights[unique] += counts\n",
    "# Normalize weights\n",
    "weights = weights / tokenized_datasets['train'].num_rows\n",
    "# Inverse frequency to give more weight to rare labels\n",
    "weights = 1.0 / weights\n",
    "# Normalize again to prevent exploding gradients\n",
    "weights = weights / np.max(weights)\n",
    "print(\"Class weights for loss function:\")\n",
    "for label_id, weight in enumerate(weights):\n",
    "    print(f\"{ID_TO_LABEL[label_id]}: {weight:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7bcac82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at Babelscape/wikineural-multilingual-ner and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([9]) in the checkpoint and torch.Size([13]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([9, 768]) in the checkpoint and torch.Size([13, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForTokenClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSdpaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=13, bias=True)\n",
      ")\n",
      "bert.embeddings.word_embeddings.weight: torch.Size([119547, 768])\n",
      "bert.embeddings.position_embeddings.weight: torch.Size([512, 768])\n",
      "bert.embeddings.token_type_embeddings.weight: torch.Size([2, 768])\n",
      "bert.embeddings.LayerNorm.weight: torch.Size([768])\n",
      "bert.embeddings.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.0.attention.self.query.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.0.attention.self.query.bias: torch.Size([768])\n",
      "bert.encoder.layer.0.attention.self.key.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.0.attention.self.key.bias: torch.Size([768])\n",
      "bert.encoder.layer.0.attention.self.value.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.0.attention.self.value.bias: torch.Size([768])\n",
      "bert.encoder.layer.0.attention.output.dense.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.0.attention.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.0.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "bert.encoder.layer.0.intermediate.dense.bias: torch.Size([3072])\n",
      "bert.encoder.layer.0.output.dense.weight: torch.Size([768, 3072])\n",
      "bert.encoder.layer.0.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.0.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.0.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.1.attention.self.query.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.1.attention.self.query.bias: torch.Size([768])\n",
      "bert.encoder.layer.1.attention.self.key.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.1.attention.self.key.bias: torch.Size([768])\n",
      "bert.encoder.layer.1.attention.self.value.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.1.attention.self.value.bias: torch.Size([768])\n",
      "bert.encoder.layer.1.attention.output.dense.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.1.attention.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.1.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "bert.encoder.layer.1.intermediate.dense.bias: torch.Size([3072])\n",
      "bert.encoder.layer.1.output.dense.weight: torch.Size([768, 3072])\n",
      "bert.encoder.layer.1.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.1.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.1.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.2.attention.self.query.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.2.attention.self.query.bias: torch.Size([768])\n",
      "bert.encoder.layer.2.attention.self.key.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.2.attention.self.key.bias: torch.Size([768])\n",
      "bert.encoder.layer.2.attention.self.value.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.2.attention.self.value.bias: torch.Size([768])\n",
      "bert.encoder.layer.2.attention.output.dense.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.2.attention.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.2.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "bert.encoder.layer.2.intermediate.dense.bias: torch.Size([3072])\n",
      "bert.encoder.layer.2.output.dense.weight: torch.Size([768, 3072])\n",
      "bert.encoder.layer.2.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.2.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.2.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.3.attention.self.query.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.3.attention.self.query.bias: torch.Size([768])\n",
      "bert.encoder.layer.3.attention.self.key.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.3.attention.self.key.bias: torch.Size([768])\n",
      "bert.encoder.layer.3.attention.self.value.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.3.attention.self.value.bias: torch.Size([768])\n",
      "bert.encoder.layer.3.attention.output.dense.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.3.attention.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.3.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "bert.encoder.layer.3.intermediate.dense.bias: torch.Size([3072])\n",
      "bert.encoder.layer.3.output.dense.weight: torch.Size([768, 3072])\n",
      "bert.encoder.layer.3.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.3.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.3.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.4.attention.self.query.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.4.attention.self.query.bias: torch.Size([768])\n",
      "bert.encoder.layer.4.attention.self.key.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.4.attention.self.key.bias: torch.Size([768])\n",
      "bert.encoder.layer.4.attention.self.value.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.4.attention.self.value.bias: torch.Size([768])\n",
      "bert.encoder.layer.4.attention.output.dense.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.4.attention.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.4.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "bert.encoder.layer.4.intermediate.dense.bias: torch.Size([3072])\n",
      "bert.encoder.layer.4.output.dense.weight: torch.Size([768, 3072])\n",
      "bert.encoder.layer.4.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.4.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.4.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.5.attention.self.query.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.5.attention.self.query.bias: torch.Size([768])\n",
      "bert.encoder.layer.5.attention.self.key.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.5.attention.self.key.bias: torch.Size([768])\n",
      "bert.encoder.layer.5.attention.self.value.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.5.attention.self.value.bias: torch.Size([768])\n",
      "bert.encoder.layer.5.attention.output.dense.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.5.attention.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.5.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "bert.encoder.layer.5.intermediate.dense.bias: torch.Size([3072])\n",
      "bert.encoder.layer.5.output.dense.weight: torch.Size([768, 3072])\n",
      "bert.encoder.layer.5.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.5.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.5.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.6.attention.self.query.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.6.attention.self.query.bias: torch.Size([768])\n",
      "bert.encoder.layer.6.attention.self.key.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.6.attention.self.key.bias: torch.Size([768])\n",
      "bert.encoder.layer.6.attention.self.value.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.6.attention.self.value.bias: torch.Size([768])\n",
      "bert.encoder.layer.6.attention.output.dense.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.6.attention.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.6.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "bert.encoder.layer.6.intermediate.dense.bias: torch.Size([3072])\n",
      "bert.encoder.layer.6.output.dense.weight: torch.Size([768, 3072])\n",
      "bert.encoder.layer.6.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.6.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.6.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.7.attention.self.query.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.7.attention.self.query.bias: torch.Size([768])\n",
      "bert.encoder.layer.7.attention.self.key.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.7.attention.self.key.bias: torch.Size([768])\n",
      "bert.encoder.layer.7.attention.self.value.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.7.attention.self.value.bias: torch.Size([768])\n",
      "bert.encoder.layer.7.attention.output.dense.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.7.attention.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.7.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "bert.encoder.layer.7.intermediate.dense.bias: torch.Size([3072])\n",
      "bert.encoder.layer.7.output.dense.weight: torch.Size([768, 3072])\n",
      "bert.encoder.layer.7.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.7.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.7.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.8.attention.self.query.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.8.attention.self.query.bias: torch.Size([768])\n",
      "bert.encoder.layer.8.attention.self.key.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.8.attention.self.key.bias: torch.Size([768])\n",
      "bert.encoder.layer.8.attention.self.value.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.8.attention.self.value.bias: torch.Size([768])\n",
      "bert.encoder.layer.8.attention.output.dense.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.8.attention.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.8.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "bert.encoder.layer.8.intermediate.dense.bias: torch.Size([3072])\n",
      "bert.encoder.layer.8.output.dense.weight: torch.Size([768, 3072])\n",
      "bert.encoder.layer.8.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.8.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.8.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.9.attention.self.query.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.9.attention.self.query.bias: torch.Size([768])\n",
      "bert.encoder.layer.9.attention.self.key.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.9.attention.self.key.bias: torch.Size([768])\n",
      "bert.encoder.layer.9.attention.self.value.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.9.attention.self.value.bias: torch.Size([768])\n",
      "bert.encoder.layer.9.attention.output.dense.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.9.attention.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.9.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "bert.encoder.layer.9.intermediate.dense.bias: torch.Size([3072])\n",
      "bert.encoder.layer.9.output.dense.weight: torch.Size([768, 3072])\n",
      "bert.encoder.layer.9.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.9.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.9.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.10.attention.self.query.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.10.attention.self.query.bias: torch.Size([768])\n",
      "bert.encoder.layer.10.attention.self.key.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.10.attention.self.key.bias: torch.Size([768])\n",
      "bert.encoder.layer.10.attention.self.value.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.10.attention.self.value.bias: torch.Size([768])\n",
      "bert.encoder.layer.10.attention.output.dense.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.10.attention.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.10.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "bert.encoder.layer.10.intermediate.dense.bias: torch.Size([3072])\n",
      "bert.encoder.layer.10.output.dense.weight: torch.Size([768, 3072])\n",
      "bert.encoder.layer.10.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.10.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.10.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.11.attention.self.query.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.self.query.bias: torch.Size([768])\n",
      "bert.encoder.layer.11.attention.self.key.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.self.key.bias: torch.Size([768])\n",
      "bert.encoder.layer.11.attention.self.value.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.self.value.bias: torch.Size([768])\n",
      "bert.encoder.layer.11.attention.output.dense.weight: torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "bert.encoder.layer.11.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "bert.encoder.layer.11.intermediate.dense.bias: torch.Size([3072])\n",
      "bert.encoder.layer.11.output.dense.weight: torch.Size([768, 3072])\n",
      "bert.encoder.layer.11.output.dense.bias: torch.Size([768])\n",
      "bert.encoder.layer.11.output.LayerNorm.weight: torch.Size([768])\n",
      "bert.encoder.layer.11.output.LayerNorm.bias: torch.Size([768])\n",
      "classifier.weight: torch.Size([13, 768])\n",
      "classifier.bias: torch.Size([13])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    # 'dslim/distilbert-NER',\n",
    "    'Babelscape/wikineural-multilingual-ner',  # Use a BERT model\n",
    "    num_labels=len(LABEL_TO_ID),\n",
    "    id2label=ID_TO_LABEL,\n",
    "    label2id=LABEL_TO_ID,\n",
    "    ignore_mismatched_sizes=True,  # Allow for mismatched sizes in the model and dataset\n",
    ")\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(model)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.size()}\")  # Print the size of each parameter for debugging\n",
    "    if 'classifier' in name:\n",
    "        # Freeze all parameters except the classifier layer\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        # Freeze other parameters to prevent overfitting\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95942c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at dslim/distilbert-NER and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([9]) in the checkpoint and torch.Size([13]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([9, 768]) in the checkpoint and torch.Size([13, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1228' max='63114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1228/63114 04:00 < 3:22:31, 5.09 it/s, Epoch 0.12/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.108000</td>\n",
       "      <td>1.792567</td>\n",
       "      <td>0.085803</td>\n",
       "      <td>0.355505</td>\n",
       "      <td>0.138241</td>\n",
       "      <td>0.303145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.734200</td>\n",
       "      <td>1.592442</td>\n",
       "      <td>0.101906</td>\n",
       "      <td>0.439446</td>\n",
       "      <td>0.165446</td>\n",
       "      <td>0.447130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 53\u001b[39m\n\u001b[32m     29\u001b[39m training_args = TrainingArguments(\n\u001b[32m     30\u001b[39m     output_dir=\u001b[33m'\u001b[39m\u001b[33m./results\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     31\u001b[39m     learning_rate=\u001b[32m2e-5\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     40\u001b[39m     eval_steps=\u001b[32m500\u001b[39m,\n\u001b[32m     41\u001b[39m )\n\u001b[32m     43\u001b[39m trainer = Trainer(\n\u001b[32m     44\u001b[39m     model=model,\n\u001b[32m     45\u001b[39m     args=training_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m     50\u001b[39m     compute_loss_func=loss_function,  \u001b[38;5;66;03m# Use the custom loss function\u001b[39;00m\n\u001b[32m     51\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# Push the model to the Hub\u001b[39;00m\n\u001b[32m     56\u001b[39m trainer.push_to_hub(commit_message=\u001b[33m\"\u001b[39m\u001b[33mTraining complete\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nlp_env/lib/python3.11/site-packages/transformers/trainer.py:2236\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2233\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   2234\u001b[39m     \u001b[38;5;66;03m# Disable progress bars when uploading models during checkpoints to avoid polluting stdout\u001b[39;00m\n\u001b[32m   2235\u001b[39m     hf_hub_utils.disable_progress_bars()\n\u001b[32m-> \u001b[39m\u001b[32m2236\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2237\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2238\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2239\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2240\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2241\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2242\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   2243\u001b[39m     hf_hub_utils.enable_progress_bars()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nlp_env/lib/python3.11/site-packages/transformers/trainer.py:2561\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2555\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m   2556\u001b[39m     tr_loss_step = \u001b[38;5;28mself\u001b[39m.training_step(model, inputs, num_items_in_batch)\n\u001b[32m   2558\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2559\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2560\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m-> \u001b[39m\u001b[32m2561\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   2562\u001b[39m ):\n\u001b[32m   2563\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2564\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n\u001b[32m   2565\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    'Babelscape/wikineural-multilingual-ner',\n",
    "    num_labels=len(LABEL_TO_ID),\n",
    "    id2label=ID_TO_LABEL,\n",
    "    label2id=LABEL_TO_ID,\n",
    "    ignore_mismatched_sizes=True,  # Allow for mismatched sizes in the model and dataset\n",
    ")\n",
    "\n",
    "def loss_function(outputs, labels, num_items_in_batch):\n",
    "    \"\"\"\n",
    "    Custom loss function to handle class imbalance using the weights we computed.\n",
    "    \"\"\"\n",
    "    logits = outputs.logits\n",
    "    loss_fct = nn.CrossEntropyLoss(weight=torch.tensor(weights, dtype=torch.float32).to(logits.device))\n",
    "    \n",
    "    # Reshape logits and labels to be compatible with CrossEntropyLoss\n",
    "    logits = logits.view(-1, model.config.num_labels)\n",
    "    labels = labels.view(-1)\n",
    "\n",
    "    # Only compute loss on non-ignored labels\n",
    "    loss = loss_fct(logits, labels)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=6,\n",
    "    weight_decay=0.0001,\n",
    "    eval_strategy='steps',  # Evaluate every epoch\n",
    "    load_best_model_at_end=True,  # Load the best model when finished training\n",
    "    save_total_limit=2,\n",
    "    push_to_hub=True,\n",
    "    eval_steps=500,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['validation'],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,  # Pass the compute_metrics function\n",
    "    compute_loss_func=loss_function,  # Use the custom loss function\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Push the model to the Hub\n",
    "trainer.push_to_hub(commit_message=\"Training complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
